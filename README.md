# Real-Time-Sign-Language-Detection
Today, around one million people use American Sign Language as their mode of communication according to the Communication Service for the Deaf. Automated two way communication between sign language and text/speech is an unsolved problem globally. We as a team are trying to tackle this issue by the use of Image Processing in real time, in which the machine sees the signs being made by a person and interprets it into the well-understood English language. We make use of Computer Vision and Supervised Model Training
